1. You should read this: https://arxiv.org/pdf/1609.08144.pdf
   about google seq2seq

2. https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings/code
   LSTM word2vec classification

3. https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py
   seq2seq char level

4. https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/21_Machine_Translation.ipynb
   a good tutorial from tf and keras (there are many tutorials there) and with explanation of some keras mistakes about sparse_cross_entropy